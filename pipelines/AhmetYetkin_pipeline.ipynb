{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extraction.orb import ORB\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "# from feature_extraction.HOG import HOG\n",
    "\n",
    "DATA_PATH=\"Caltech20\"\n",
    "TRAINING_DIR=os.path.join(DATA_PATH, \"training\")\n",
    "TEST_DIR=os.path.join(DATA_PATH, \"testing\")\n",
    "\n",
    "classes = []\n",
    "features = {}\n",
    "all_descriptor = []\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "\n",
    "for class_name in sorted(os.listdir(TRAINING_DIR)):\n",
    "    classes.append(class_name)\n",
    "    features[class_name] = {}\n",
    "    class_dir = os.path.join(TRAINING_DIR, class_name)\n",
    "    for file_name in sorted(os.listdir(class_dir)):\n",
    "        filename = os.path.join(class_dir, file_name)\n",
    "#        kp, des = ORB.compute_file(filename)\n",
    "        img = imread(filename,as_gray=True)\n",
    "        resized_img = resize(img, (128,64))\n",
    "        fd, hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8, 8), \n",
    "                    cells_per_block=(2, 2), visualize=True, multichannel=False)\n",
    "        # hog_image,fd = HOG(filename)\n",
    "        \n",
    "        if hog_image is not None:\n",
    "            # hog_image = hog_image[:32]\n",
    "            features[class_name][file_name] = hog_image\n",
    "            all_descriptor.extend(hog_image)\n",
    "\n",
    "kmeans = KMeans(100)\n",
    "kmeans.fit(all_descriptor)\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "\n",
    "from feature_quantization.bag_of_visual_words import get_histogram\n",
    "\n",
    "histograms = {}\n",
    "for c_name in features:\n",
    "    histograms[c_name] = []\n",
    "    for img in features[c_name]:\n",
    "        histograms[c_name].append(get_histogram(features[c_name][img], centers))\n",
    "        \n",
    "X = []\n",
    "Y = []\n",
    "for c in histograms:\n",
    "    X.extend(histograms[c])\n",
    "    Y.extend([c] * len(histograms[c]))\n",
    "    \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "# classifier.fit(X, Y)\n",
    "\n",
    "test_classes = []\n",
    "test_features = {}\n",
    "\n",
    "testX = []\n",
    "testY = []\n",
    "\n",
    "for class_name in sorted(os.listdir(TEST_DIR)):\n",
    "    class_dir = os.path.join(TEST_DIR, class_name)\n",
    "    for file_name in sorted(os.listdir(class_dir)):\n",
    "        filename = os.path.join(class_dir, file_name)\n",
    "        img = imread(filename,as_gray=True)\n",
    "        resized_img = resize(img, (128,64))\n",
    "        fd, hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8, 8), \n",
    "                    cells_per_block=(2, 2), visualize=True, multichannel=False)\n",
    "        if hog_image is not None:\n",
    "            # hog_image = hog_image[:32]\n",
    "            histogram = get_histogram(hog_image, centers)\n",
    "            testX.append(histogram)\n",
    "            testY.append(class_name)\n",
    "\n",
    "classifier.score(testX, testY)\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "training_labels_encoded = le.fit_transform(Y)\n",
    "testing_labels_encoded = le.transform(testY)\n",
    "keys = le.classes_\n",
    "values = le.transform(le.classes_)\n",
    "dictionary = dict(zip(keys, values))\n",
    "\n",
    "#TRAINING RANDOM FOREST AND RUNING IT ON TEST DATA TO MAKE PREDICTIONS\n",
    "classifier.fit(X, training_labels_encoded)\n",
    "predictions = classifier.predict(testX)\n",
    "target_names = ['Faces','airplanes','anchor','background','barrel','camera','car_side','dalmatian','ferry','headphone','lamp','pizza','pyramid','snoopy','soccer_ball','stop_sign','strawberry','sunflower','water_lilly','windsor_chair','yin_yang']\n",
    "\n",
    "#EVALUATION PART WHICH CONSISTS OF MEAN F1-SCORE, PER-CLASS (F1-SCORE, PRECISION, RECALL) AND CONFUSION MATRIX\n",
    "print(classification_report(testing_labels_encoded, predictions, target_names=target_names,zero_division=1))\n",
    "cm = confusion_matrix(testing_labels_encoded, predictions, labels=values)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = keys)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
